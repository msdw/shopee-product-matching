{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039207,
     "end_time": "2021-05-10T14:10:45.418927",
     "exception": false,
     "start_time": "2021-05-10T14:10:45.379720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Effnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:10:45.499632Z",
     "iopub.status.busy": "2021-05-10T14:10:45.499045Z",
     "iopub.status.idle": "2021-05-10T14:11:39.486534Z",
     "shell.execute_reply": "2021-05-10T14:11:39.485832Z"
    },
    "papermill": {
     "duration": 54.031172,
     "end_time": "2021-05-10T14:11:39.486734",
     "exception": false,
     "start_time": "2021-05-10T14:10:45.455562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ../input/externalshopee/Keras_Applications-1.0.8-py3-none-any.whl >> /dev/null\n",
    "!pip install ../input/externalshopee/efficientnet-1.1.1-py3-none-any.whl >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:39.568334Z",
     "iopub.status.busy": "2021-05-10T14:11:39.567456Z",
     "iopub.status.idle": "2021-05-10T14:11:49.349357Z",
     "shell.execute_reply": "2021-05-10T14:11:49.348337Z"
    },
    "papermill": {
     "duration": 9.825059,
     "end_time": "2021-05-10T14:11:49.349511",
     "exception": false,
     "start_time": "2021-05-10T14:11:39.524452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:701: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml import PCA\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:49.436665Z",
     "iopub.status.busy": "2021-05-10T14:11:49.434851Z",
     "iopub.status.idle": "2021-05-10T14:11:49.437281Z",
     "shell.execute_reply": "2021-05-10T14:11:49.437675Z"
    },
    "papermill": {
     "duration": 0.050582,
     "end_time": "2021-05-10T14:11:49.437819",
     "exception": false,
     "start_time": "2021-05-10T14:11:49.387237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = [512, 512]\n",
    "# Seed\n",
    "SEED = 42\n",
    "# Verbosity\n",
    "VERBOSE = 1\n",
    "# Number of classes\n",
    "N_CLASSES = 11014\n",
    "\n",
    "# Paths\n",
    "WORK_DIR = \"../input/shopee-product-matching/\"\n",
    "\n",
    "EFFNET_B3 = '../input/all-data-shopee-efficientnetb3-arcmarginproduct-v2/EfficientNetB3_512_42.h5'\n",
    "EFFNET_B4 = '../input/all-data-shopee-efficientnetb4-coslr-to-ens/EfficientNetB4_384_42.h5'\n",
    "# EFFNET_B4 = '../input/all-data-shopee-efficientnetb4-to-ens/EfficientNetB4_384_42.h5'\n",
    "EFFNET_B4_2 = '../input/last-validation-data-shopee-efficientnetb4/EfficientNetB4_456_2020.h5'\n",
    "EFFNET_B5 = '../input/all-data-efficientnetb5-more-aug-to-ens/EfficientNetB5_512_42.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:49.696933Z",
     "iopub.status.busy": "2021-05-10T14:11:49.695984Z",
     "iopub.status.idle": "2021-05-10T14:11:54.691042Z",
     "shell.execute_reply": "2021-05-10T14:11:54.690575Z"
    },
    "papermill": {
     "duration": 5.216616,
     "end_time": "2021-05-10T14:11:54.691177",
     "exception": false,
     "start_time": "2021-05-10T14:11:49.474561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will restrict TensorFlow to max 2GB GPU RAM\n",
      "then RAPIDS can use 14GB GPU RAM\n"
     ]
    }
   ],
   "source": [
    "# RESTRICT TENSORFLOW TO 2GB OF GPU RAM\n",
    "# SO THAT WE HAVE 14GB RAM FOR RAPIDS\n",
    "LIMIT = 2.0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
    "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:54.777013Z",
     "iopub.status.busy": "2021-05-10T14:11:54.776460Z",
     "iopub.status.idle": "2021-05-10T14:11:54.788201Z",
     "shell.execute_reply": "2021-05-10T14:11:54.787645Z"
    },
    "papermill": {
     "duration": 0.058784,
     "end_time": "2021-05-10T14:11:54.788389",
     "exception": false,
     "start_time": "2021-05-10T14:11:54.729605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flag to get cv score\n",
    "GET_CV = False\n",
    "# Flag to check ram allocations (debug)\n",
    "CHECK_SUB = False\n",
    "\n",
    "df = pd.read_csv(WORK_DIR + 'test.csv')\n",
    "# If we are comitting, replace train set for test set and dont get cv\n",
    "if len(df) > 3:\n",
    "    GET_CV = False\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:54.874738Z",
     "iopub.status.busy": "2021-05-10T14:11:54.873867Z",
     "iopub.status.idle": "2021-05-10T14:11:54.876834Z",
     "shell.execute_reply": "2021-05-10T14:11:54.876423Z"
    },
    "papermill": {
     "duration": 0.048799,
     "end_time": "2021-05-10T14:11:54.876957",
     "exception": false,
     "start_time": "2021-05-10T14:11:54.828158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get our f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "# Function to combine predictions\n",
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
    "    return ' '.join( np.unique(x) )\n",
    "\n",
    "def norm(x):\n",
    "    return x / np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:54.986316Z",
     "iopub.status.busy": "2021-05-10T14:11:54.978186Z",
     "iopub.status.idle": "2021-05-10T14:11:54.989311Z",
     "shell.execute_reply": "2021-05-10T14:11:54.988824Z"
    },
    "papermill": {
     "duration": 0.074018,
     "end_time": "2021-05-10T14:11:54.989450",
     "exception": false,
     "start_time": "2021-05-10T14:11:54.915432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to read out dataset\n",
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv(WORK_DIR + 'train.csv')\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis = 0)\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = WORK_DIR + 'train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv(WORK_DIR + 'test.csv')\n",
    "        df_cu = cudf.DataFrame(df)\n",
    "        image_paths = WORK_DIR + 'test_images/' + df['image']\n",
    "        \n",
    "    return df, df_cu, image_paths\n",
    "\n",
    "# Function to decode our images\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels = 3)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "# Function to read our test image and return image\n",
    "def read_image(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_image(image)\n",
    "    return image\n",
    "\n",
    "# Function to get our dataset that read images\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "# Arcmarginproduct class keras layer\n",
    "class ArcMarginProduct(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Implements large margin arc distance.\n",
    "\n",
    "    Reference:\n",
    "        https://arxiv.org/pdf/1801.07698.pdf\n",
    "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
    "            blob/master/src/modeling/metric_learning.py\n",
    "    '''\n",
    "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
    "                 ls_eps=0.0, **kwargs):\n",
    "\n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = tf.math.cos(m)\n",
    "        self.sin_m = tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "\n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'ls_eps': self.ls_eps,\n",
    "            'easy_margin': self.easy_margin,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "\n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer='glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "# Function to get the embeddings of our images with the fine-tuned model\n",
    "def get_image_embeddings(image_paths, model_weight):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5,\n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n",
    "    if 'B3' in model_weight:\n",
    "        x = efn.EfficientNetB3(weights = None, include_top = False)(inp)\n",
    "    elif 'B4' in model_weight:\n",
    "        x = efn.EfficientNetB4(weights = None, include_top = False)(inp)\n",
    "    elif 'B5' in model_weight:\n",
    "        x = efn.EfficientNetB5(weights = None, include_top = False)(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "        \n",
    "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n",
    "    model.load_weights(model_weight)\n",
    "    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(image_paths[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings\n",
    "\n",
    "\"\"\"\n",
    "KNN\n",
    "\"\"\"\n",
    "# Function to get 50 nearest neighbors of each image and apply a distance threshold to maximize cv\n",
    "def get_neighbors(df, embeddings, KNN = 50, th = 0.3):\n",
    "    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\n",
    "#     model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    predictions = []\n",
    "    for k in tqdm(range(embeddings.shape[0])):\n",
    "        idx = np.where(distances[k,] < th)[0]\n",
    "        ids = indices[k,idx]\n",
    "        posting_ids = df['posting_id'].iloc[ids].values\n",
    "        predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:55.080066Z",
     "iopub.status.busy": "2021-05-10T14:11:55.079367Z",
     "iopub.status.idle": "2021-05-10T14:11:55.119421Z",
     "shell.execute_reply": "2021-05-10T14:11:55.118866Z"
    },
    "papermill": {
     "duration": 0.091167,
     "end_time": "2021-05-10T14:11:55.119554",
     "exception": false,
     "start_time": "2021-05-10T14:11:55.028387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, df_cu, image_paths = read_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038091,
     "end_time": "2021-05-10T14:11:55.195825",
     "exception": false,
     "start_time": "2021-05-10T14:11:55.157734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Nfnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:55.277674Z",
     "iopub.status.busy": "2021-05-10T14:11:55.277023Z",
     "iopub.status.idle": "2021-05-10T14:11:58.826903Z",
     "shell.execute_reply": "2021-05-10T14:11:58.826439Z"
    },
    "papermill": {
     "duration": 3.592874,
     "end_time": "2021-05-10T14:11:58.827063",
     "exception": false,
     "start_time": "2021-05-10T14:11:55.234189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os \n",
    "import cv2\n",
    "import timm\n",
    "import random \n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import albumentations as A \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:58.912816Z",
     "iopub.status.busy": "2021-05-10T14:11:58.912063Z",
     "iopub.status.idle": "2021-05-10T14:11:58.919295Z",
     "shell.execute_reply": "2021-05-10T14:11:58.918712Z"
    },
    "papermill": {
     "duration": 0.054325,
     "end_time": "2021-05-10T14:11:58.919417",
     "exception": false,
     "start_time": "2021-05-10T14:11:58.865092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \n",
    "    img_size = 512\n",
    "    batch_size = 12\n",
    "    seed = 42\n",
    "    \n",
    "    device = 'cuda'\n",
    "    classes = 11014\n",
    "    \n",
    "    model_name = 'eca_nfnet_l1'\n",
    "    model_path = '../input/shopeetorchmodel/nfnet_l1_mish_all_data_augs_20_epo.pt'\n",
    "#     model_name = 'eca_nfnet_l0'\n",
    "#     model_path = '../input/shopeetorchmodel/nfnet_l0_mish_all_data_augs_25_epo.pt'\n",
    "    \n",
    "    scale = 30 \n",
    "    margin = 0.5\n",
    "    \n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:59.030745Z",
     "iopub.status.busy": "2021-05-10T14:11:59.019473Z",
     "iopub.status.idle": "2021-05-10T14:11:59.047145Z",
     "shell.execute_reply": "2021-05-10T14:11:59.046703Z"
    },
    "papermill": {
     "duration": 0.089175,
     "end_time": "2021-05-10T14:11:59.047278",
     "exception": false,
     "start_time": "2021-05-10T14:11:58.958103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_transforms():\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(CFG.img_size,CFG.img_size,always_apply=True),\n",
    "            A.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "class ShopeeDatasetTorchImage(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.augmentations = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_paths.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']       \n",
    "    \n",
    "        return image,torch.tensor(1)\n",
    "    \n",
    "class ArcMarginProductTorchImage(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProductTorchImage, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "\n",
    "        return output\n",
    "\n",
    "class ShopeeModelTorchImage(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes,\n",
    "        model_name = CFG.model_name,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = False):\n",
    "\n",
    "        super(ShopeeModelTorchImage,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif model_name == 'eca_nfnet_l0':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "            \n",
    "        elif model_name == 'eca_nfnet_l1':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProductTorchImage(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        #logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class Mish_func(torch.autograd.Function):\n",
    "    \n",
    "    \"\"\"from: https://github.com/tyunist/memory_efficient_mish_swish/blob/master/mish.py\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.tanh(F.softplus(i))\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "  \n",
    "        v = 1. + i.exp()\n",
    "        h = v.log() \n",
    "        grad_gh = 1./h.cosh().pow_(2) \n",
    "\n",
    "        # Note that grad_hv * grad_vx = sigmoid(x)\n",
    "        #grad_hv = 1./v  \n",
    "        #grad_vx = i.exp()\n",
    "        \n",
    "        grad_hx = i.sigmoid()\n",
    "        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n",
    "        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n",
    "        \n",
    "        return grad_output * grad_f \n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    def forward(self, input_tensor):\n",
    "        return Mish_func.apply(input_tensor)\n",
    "\n",
    "def replace_activations(model, existing_layer, new_layer):\n",
    "    \n",
    "    \"\"\"A function for replacing existing activation layers\"\"\"\n",
    "    \n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n",
    "\n",
    "        if type(module) == existing_layer:\n",
    "            layer_old = module\n",
    "            layer_new = new_layer\n",
    "            model._modules[name] = layer_new\n",
    "    return model\n",
    "\n",
    "def get_image_embeddings_torch(image_paths, model_name = CFG.model_name):\n",
    "    embeds = []\n",
    "    \n",
    "    model = ShopeeModelTorchImage(model_name = model_name)\n",
    "    model.eval()\n",
    "    \n",
    "    if model_name == 'eca_nfnet_l0' or model_name == 'eca_nfnet_l1':\n",
    "        model = replace_activations(model, torch.nn.SiLU, Mish())\n",
    "\n",
    "    model.load_state_dict(torch.load(CFG.model_path))\n",
    "    model = model.to(CFG.device)\n",
    "    \n",
    "    image_dataset = ShopeeDatasetTorchImage(image_paths=image_paths,transforms=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "    \n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038954,
     "end_time": "2021-05-10T14:11:59.125374",
     "exception": false,
     "start_time": "2021-05-10T14:11:59.086420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:11:59.210262Z",
     "iopub.status.busy": "2021-05-10T14:11:59.209733Z",
     "iopub.status.idle": "2021-05-10T14:12:02.419739Z",
     "shell.execute_reply": "2021-05-10T14:12:02.418668Z"
    },
    "papermill": {
     "duration": 3.254672,
     "end_time": "2021-05-10T14:12:02.419895",
     "exception": false,
     "start_time": "2021-05-10T14:11:59.165223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://adrien.barbaresi.eu/blog/simple-multilingual-lemmatizer-python.html\n",
    "!cp -r ../input/shopee-simplemma/simplemma-main/* ./\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import simplemma\n",
    "from tqdm import tqdm\n",
    "from simplemma import text_lemmatizer\n",
    "langdata = simplemma.load_data('id')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:02.517418Z",
     "iopub.status.busy": "2021-05-10T14:12:02.516712Z",
     "iopub.status.idle": "2021-05-10T14:12:04.475020Z",
     "shell.execute_reply": "2021-05-10T14:12:04.474516Z"
    },
    "papermill": {
     "duration": 2.015302,
     "end_time": "2021-05-10T14:12:04.475163",
     "exception": false,
     "start_time": "2021-05-10T14:12:02.459861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_units(text):\n",
    "    \"\"\"\n",
    "    split numbers and characters in a string\n",
    "    Ex. ex15ap => ex 15 ap\n",
    "    \"\"\"\n",
    "    sub = []\n",
    "    char, num = \"\", \"\"\n",
    "    text = text.strip()\n",
    "    for letter in text:\n",
    "        if letter.isdigit():\n",
    "            if char:\n",
    "                sub.append(char)\n",
    "                char = \"\"\n",
    "            num += letter\n",
    "        else:\n",
    "            if num:\n",
    "                sub.append(num)\n",
    "                num = \"\"\n",
    "            char += letter\n",
    "    sub.append(char) if char else sub.append(num)\n",
    "    return ' '.join(sub)\n",
    "\n",
    "def uniform_units(text):\n",
    "    words = text.split()\n",
    "    words = ['gram' if w in ['g', 'gr', 'grm'] else w for w in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "e_commerce_stopwords = ['ready', 'stock', 'free', 'gift', 'jaring', 'sabun', 'siap', 'kirim', 'diskon', '11', 'buruan',\n",
    "                        'order', 'open', 'reseller', 'langsung', 'readystock', 'cod', 'bisa', 'promo', 'promotion',\n",
    "                        'best', 'seller', 'sku', 'fast', 'delivery', 'bayar', 'ditempat', 'belanja', 'aman', 'nyaman',\n",
    "                        'pos', 'today', 'hot', 'di', 'tempat', 'terlaris', 'garansi', 'stok', 'mohon', 'baca', \n",
    "                        'deskripsi', 'description', 'resmi', 'distributor', 'sold', 'out', 'ress', 'distri',\n",
    "                        'ori', 'origin', 'original', 'new', 'import', 'lokal'\n",
    "                       ]\n",
    "\n",
    "def remove_sw(text):\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in e_commerce_stopwords]\n",
    "    return ' '.join(words) if len(words) > 0 else text\n",
    "\n",
    "# text cleaning V5\n",
    "def text_preprocess(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove unicode emojis\n",
    "    text = re.sub(r'\\\\x(.){2}', ' ', text)\n",
    "    \n",
    "    # remove punctuations\n",
    "    character_list = string.punctuation\n",
    "    text = text.translate(str.maketrans(character_list, ' ' * len(character_list)))\n",
    "    \n",
    "    # split& uniform units\n",
    "    text = split_units(text)\n",
    "    text = uniform_units(text)\n",
    "    \n",
    "    # lemmatization id\n",
    "    words = text_lemmatizer(text, langdata)\n",
    "    \n",
    "    # lemmatization en\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
    "    \n",
    "    # remove stopwords\n",
    "    text = remove_sw(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['title_to_use'] = df['title'].apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:04.564089Z",
     "iopub.status.busy": "2021-05-10T14:12:04.563483Z",
     "iopub.status.idle": "2021-05-10T14:12:04.567287Z",
     "shell.execute_reply": "2021-05-10T14:12:04.567672Z"
    },
    "papermill": {
     "duration": 0.053891,
     "end_time": "2021-05-10T14:12:04.567836",
     "exception": false,
     "start_time": "2021-05-10T14:12:04.513945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", binary=True)\n",
    "tfidf_vec.fit(df['title_to_use'])\n",
    "dictionary = tfidf_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:04.655248Z",
     "iopub.status.busy": "2021-05-10T14:12:04.654665Z",
     "iopub.status.idle": "2021-05-10T14:12:04.966817Z",
     "shell.execute_reply": "2021-05-10T14:12:04.964961Z"
    },
    "papermill": {
     "duration": 0.360343,
     "end_time": "2021-05-10T14:12:04.966944",
     "exception": false,
     "start_time": "2021-05-10T14:12:04.606601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 258.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1990aec06f4042108cfe995fa7699f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Remove duplicates like : fresh care=>freshcare\"\"\"\n",
    "dict_dup = {}\n",
    "\n",
    "for text in tqdm(df['title_to_use']):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    if len(words) < 2: continue\n",
    "    # bigrams\n",
    "    bigrams = nltk.bigrams(words)\n",
    "    for grams in bigrams:\n",
    "        tmp = ''.join(grams)\n",
    "        if tmp in dictionary and tmp not in dict_dup and len(tmp) >= 6 and not tmp.isdigit():\n",
    "            k = ' '.join(grams)\n",
    "            dict_dup[k] = tmp\n",
    "    # trigrams\n",
    "    trigrams = nltk.trigrams(words)\n",
    "    for grams in trigrams:\n",
    "        tmp = ''.join(grams)\n",
    "        if tmp in dictionary and tmp not in dict_dup and len(tmp) >= 9 and not tmp.isdigit():\n",
    "            k = ' '.join(grams)\n",
    "            dict_dup[k] = tmp\n",
    "\n",
    "print(len(dict_dup))\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = text.split()\n",
    "    bigrams = [' '.join(words[i:i+2]) for i in range(len(words)-2+1)]\n",
    "    trigrams = [' '.join(words[i:i+3]) for i in range(len(words)-3+1)]\n",
    "    for g in bigrams + trigrams:\n",
    "        if g in dict_dup:\n",
    "            text = text.replace(g, dict_dup[g])\n",
    "    return text\n",
    "\n",
    "df['title_to_use_'] = df['title_to_use'].progress_apply(remove_duplicates)\n",
    "del dictionary; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:05.072313Z",
     "iopub.status.busy": "2021-05-10T14:12:05.071499Z",
     "iopub.status.idle": "2021-05-10T14:12:05.074473Z",
     "shell.execute_reply": "2021-05-10T14:12:05.074062Z"
    },
    "papermill": {
     "duration": 0.066157,
     "end_time": "2021-05-10T14:12:05.074594",
     "exception": false,
     "start_time": "2021-05-10T14:12:05.008437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def text_knn(df, text_tensor, K, th, chunk = 128):\n",
    "    out_preds = []\n",
    "    for i in tqdm(list(range(0, df.shape[0], chunk)) + [df.shape[0]-chunk]):\n",
    "        arr = text_tensor[i : i + chunk] @ text_tensor.T\n",
    "        if len(df) > 3: \n",
    "            indices = torch.nonzero((arr > th) & (arr >= arr.sort(descending=True).values[:,K-1].reshape(arr.shape[0],-1)))\n",
    "        else:\n",
    "            indices = torch.nonzero(arr > th)\n",
    "\n",
    "        preds = dict()\n",
    "        for k in range(arr.shape[0]):\n",
    "            preds[k] = []\n",
    "        for ind in range(indices.size(0)):\n",
    "            preds[indices[ind, 0].item()].append(indices[ind, 1].item())\n",
    "\n",
    "        out_preds.extend([(df.iloc[k].posting_id, df.iloc[v].posting_id.tolist()) for k, v in preds.items()])\n",
    "    return out_preds[:df.shape[0]]\n",
    "\n",
    "def text_knn_2(df, tensor1, tensor2, K, th, chunk = 128):\n",
    "    out_preds = []\n",
    "    for i in tqdm(list(range(0, df.shape[0], chunk)) + [df.shape[0]-chunk]):\n",
    "        arr = tensor1[i : i + chunk] @ tensor1.T + (tensor2[i : i + chunk] @ tensor2.T)\n",
    "        if len(df) > 3: \n",
    "            indices = torch.nonzero((arr > th) & (arr >= arr.sort(descending=True).values[:,K-1].reshape(arr.shape[0],-1)))\n",
    "        else:\n",
    "            indices = torch.nonzero(arr > th)\n",
    "\n",
    "        preds = dict()\n",
    "        for k in range(arr.shape[0]):\n",
    "            preds[k] = []\n",
    "        for ind in range(indices.size(0)):\n",
    "            preds[indices[ind, 0].item()].append(indices[ind, 1].item())\n",
    "\n",
    "        out_preds.extend([(df.iloc[k].posting_id, df.iloc[v].posting_id.tolist()) for k, v in preds.items()])\n",
    "    return out_preds[:df.shape[0]]\n",
    "\n",
    "def text_knn_3(df, tensor1, tensor2, tensor3, weight1, weight2, weight3, K, th, chunk = 128):\n",
    "    out_preds = []\n",
    "    for i in tqdm(list(range(0, df.shape[0], chunk)) + [df.shape[0]-chunk]):\n",
    "        arr = (tensor1[i : i + chunk] @ tensor1.T) * weight1 + \\\n",
    "              (tensor2[i : i + chunk] @ tensor2.T) * weight2 + \\\n",
    "              (tensor3[i : i + chunk] @ tensor3.T) * weight3\n",
    "        if len(df) > 3: \n",
    "            indices = torch.nonzero((arr > th) & (arr >= arr.sort(descending=True).values[:,K-1].reshape(arr.shape[0],-1)))\n",
    "        else:\n",
    "            indices = torch.nonzero(arr > th)\n",
    "\n",
    "        preds = dict()\n",
    "        for k in range(arr.shape[0]):\n",
    "            preds[k] = []\n",
    "        for ind in range(indices.size(0)):\n",
    "            preds[indices[ind, 0].item()].append(indices[ind, 1].item())\n",
    "\n",
    "        out_preds.extend([(df.iloc[k].posting_id, df.iloc[v].posting_id.tolist()) for k, v in preds.items()])\n",
    "    return out_preds[:df.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041027,
     "end_time": "2021-05-10T14:12:05.156467",
     "exception": false,
     "start_time": "2021-05-10T14:12:05.115440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:05.245194Z",
     "iopub.status.busy": "2021-05-10T14:12:05.244459Z",
     "iopub.status.idle": "2021-05-10T14:12:05.316682Z",
     "shell.execute_reply": "2021-05-10T14:12:05.316160Z"
    },
    "papermill": {
     "duration": 0.118656,
     "end_time": "2021-05-10T14:12:05.316805",
     "exception": false,
     "start_time": "2021-05-10T14:12:05.198149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "import transformers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:05.404338Z",
     "iopub.status.busy": "2021-05-10T14:12:05.403688Z",
     "iopub.status.idle": "2021-05-10T14:12:07.572524Z",
     "shell.execute_reply": "2021-05-10T14:12:07.571529Z"
    },
    "papermill": {
     "duration": 2.215108,
     "end_time": "2021-05-10T14:12:07.572680",
     "exception": false,
     "start_time": "2021-05-10T14:12:05.357572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "\n",
    "transformer_model = '../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer'\n",
    "TOKENIZER = transformers.AutoTokenizer.from_pretrained(transformer_model)\n",
    "\n",
    "TEXT_MODEL_PATH = '../input/best-multilingual-model/sentence_transfomer_xlm_best_loss_num_epochs_25_arcface.bin'\n",
    "\n",
    "model_params = {\n",
    "    'n_classes':11014,\n",
    "    'model_name':transformer_model,\n",
    "    'use_fc':False,\n",
    "    'fc_dim':512,\n",
    "    'dropout':0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:07.676532Z",
     "iopub.status.busy": "2021-05-10T14:12:07.674650Z",
     "iopub.status.idle": "2021-05-10T14:12:07.677235Z",
     "shell.execute_reply": "2021-05-10T14:12:07.677645Z"
    },
    "papermill": {
     "duration": 0.062943,
     "end_time": "2021-05-10T14:12:07.677807",
     "exception": false,
     "start_time": "2021-05-10T14:12:07.614864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv.reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "        \n",
    "        text = row.title\n",
    "        \n",
    "        text = TOKENIZER(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        input_ids = text['input_ids'][0]\n",
    "        attention_mask = text['attention_mask'][0]  \n",
    "        \n",
    "        return input_ids, attention_mask\n",
    "    \n",
    "class ShopeeNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name='bert-base-uncased',\n",
    "                 use_fc=False,\n",
    "                 fc_dim=512,\n",
    "                 dropout=0.0):\n",
    "        \"\"\"\n",
    "        :param n_classes:\n",
    "        :param model_name: name of model from pretrainedmodels\n",
    "            e.g. resnet50, resnext101_32x4d, pnasnet5large\n",
    "        :param pooling: One of ('SPoC', 'MAC', 'RMAC', 'GeM', 'Rpool', 'Flatten', 'CompactBilinearPooling')\n",
    "        :param loss_module: One of ('arcface', 'cosface', 'softmax')\n",
    "        \"\"\"\n",
    "        super(ShopeeNet, self).__init__()\n",
    "\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name)\n",
    "        final_in_features = self.transformer.config.hidden_size\n",
    "        \n",
    "        self.use_fc = use_fc\n",
    "    \n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids,attention_mask):\n",
    "        feature = self.extract_feat(input_ids,attention_mask)\n",
    "        return F.normalize(feature)\n",
    "\n",
    "    def extract_feat(self, input_ids,attention_mask):\n",
    "        x = self.transformer(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "        features = x[0]\n",
    "        features = features[:,0,:]\n",
    "\n",
    "        if self.use_fc:\n",
    "            features = self.dropout(features)\n",
    "            features = self.fc(features)\n",
    "            features = self.bn(features)\n",
    "\n",
    "        return features\n",
    "    \n",
    "def get_text_embeddings(df):\n",
    "    embeds = []\n",
    "    \n",
    "    model = ShopeeNet(**model_params)\n",
    "    model.eval()\n",
    "    \n",
    "    model.load_state_dict(dict(list(torch.load(TEXT_MODEL_PATH).items())[:-1]))\n",
    "    model = model.to(device)\n",
    "\n",
    "    text_dataset = ShopeeDataset(df)\n",
    "    text_loader = torch.utils.data.DataLoader(\n",
    "        text_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask in tqdm(text_loader): \n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            feat = model(input_ids, attention_mask)\n",
    "            text_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(text_embeddings)\n",
    "    \n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042727,
     "end_time": "2021-05-10T14:12:07.762679",
     "exception": false,
     "start_time": "2021-05-10T14:12:07.719952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04179,
     "end_time": "2021-05-10T14:12:07.846610",
     "exception": false,
     "start_time": "2021-05-10T14:12:07.804820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040526,
     "end_time": "2021-05-10T14:12:07.928096",
     "exception": false,
     "start_time": "2021-05-10T14:12:07.887570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1.1 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:08.034225Z",
     "iopub.status.busy": "2021-05-10T14:12:08.032086Z",
     "iopub.status.idle": "2021-05-10T14:12:12.427541Z",
     "shell.execute_reply": "2021-05-10T14:12:12.427025Z"
    },
    "papermill": {
     "duration": 4.458581,
     "end_time": "2021-05-10T14:12:12.427671",
     "exception": false,
     "start_time": "2021-05-10T14:12:07.969090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.64 s, sys: 643 ms, total: 2.28 s\n",
      "Wall time: 4.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vec = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", binary=True)\n",
    "tfidf_embeddings = tfidf_vec.fit_transform(df['title_to_use_']).toarray().astype(np.float32)\n",
    "tfidf_tensor = torch.from_numpy(tfidf_embeddings).to(device)\n",
    "del tfidf_embeddings, tfidf_vec; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:12.786194Z",
     "iopub.status.busy": "2021-05-10T14:12:12.785598Z",
     "iopub.status.idle": "2021-05-10T14:12:12.791330Z",
     "shell.execute_reply": "2021-05-10T14:12:12.790848Z"
    },
    "papermill": {
     "duration": 0.318167,
     "end_time": "2021-05-10T14:12:12.791459",
     "exception": false,
     "start_time": "2021-05-10T14:12:12.473292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042687,
     "end_time": "2021-05-10T14:12:12.877233",
     "exception": false,
     "start_time": "2021-05-10T14:12:12.834546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1.2 SBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:12.968851Z",
     "iopub.status.busy": "2021-05-10T14:12:12.968322Z",
     "iopub.status.idle": "2021-05-10T14:12:43.931906Z",
     "shell.execute_reply": "2021-05-10T14:12:43.931278Z"
    },
    "papermill": {
     "duration": 31.011859,
     "end_time": "2021-05-10T14:12:43.932230",
     "exception": false,
     "start_time": "2021-05-10T14:12:12.920371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our text embeddings shape is (3, 768)\n",
      "CPU times: user 6.79 s, sys: 2.61 s, total: 9.4 s\n",
      "Wall time: 31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bert_embeddings = get_text_embeddings(df)\n",
    "bert_embeddings = np.apply_along_axis(norm, 1, bert_embeddings)\n",
    "\n",
    "bert_tensor = torch.from_numpy(bert_embeddings).to(device)\n",
    "del bert_embeddings; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044388,
     "end_time": "2021-05-10T14:12:44.021071",
     "exception": false,
     "start_time": "2021-05-10T14:12:43.976683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1.N All text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043604,
     "end_time": "2021-05-10T14:12:44.109069",
     "exception": false,
     "start_time": "2021-05-10T14:12:44.065465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044329,
     "end_time": "2021-05-10T14:12:44.198599",
     "exception": false,
     "start_time": "2021-05-10T14:12:44.154270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2.1 Effnet B3 (loss 14.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:44.292758Z",
     "iopub.status.busy": "2021-05-10T14:12:44.292227Z",
     "iopub.status.idle": "2021-05-10T14:12:55.846969Z",
     "shell.execute_reply": "2021-05-10T14:12:55.846433Z"
    },
    "papermill": {
     "duration": 11.604491,
     "end_time": "2021-05-10T14:12:55.847114",
     "exception": false,
     "start_time": "2021-05-10T14:12:44.242623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 1536)\n",
      "CPU times: user 6.94 s, sys: 528 ms, total: 7.47 s\n",
      "Wall time: 11.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35600"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "IMAGE_SIZE = [512, 512]\n",
    "effb3_embeddings = get_image_embeddings(image_paths, EFFNET_B3)\n",
    "effb3_embeddings = np.apply_along_axis(norm, 1, effb3_embeddings)\n",
    "\n",
    "image_embeddings = effb3_embeddings\n",
    "del effb3_embeddings; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044206,
     "end_time": "2021-05-10T14:12:55.936722",
     "exception": false,
     "start_time": "2021-05-10T14:12:55.892516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2.2 Nfnet (loss 14.31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:12:56.037243Z",
     "iopub.status.busy": "2021-05-10T14:12:56.036458Z",
     "iopub.status.idle": "2021-05-10T14:13:01.792364Z",
     "shell.execute_reply": "2021-05-10T14:13:01.793824Z"
    },
    "papermill": {
     "duration": 5.812747,
     "end_time": "2021-05-10T14:13:01.794037",
     "exception": false,
     "start_time": "2021-05-10T14:12:55.981290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for eca_nfnet_l1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 512)\n",
      "CPU times: user 1.69 s, sys: 345 ms, total: 2.04 s\n",
      "Wall time: 5.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if True:\n",
    "    nfnet_embeddings = get_image_embeddings_torch(image_paths.values)\n",
    "    nfnet_embeddings = np.apply_along_axis(norm, 1, nfnet_embeddings)\n",
    "    \n",
    "    image_embeddings = np.concatenate([image_embeddings, nfnet_embeddings], axis=1)\n",
    "    del nfnet_embeddings; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049075,
     "end_time": "2021-05-10T14:13:01.889713",
     "exception": false,
     "start_time": "2021-05-10T14:13:01.840638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2.3 Effnet B4 (cosLR, 384, loss 14.34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:01.995057Z",
     "iopub.status.busy": "2021-05-10T14:13:01.990432Z",
     "iopub.status.idle": "2021-05-10T14:13:13.133797Z",
     "shell.execute_reply": "2021-05-10T14:13:13.133047Z"
    },
    "papermill": {
     "duration": 11.197847,
     "end_time": "2021-05-10T14:13:13.133988",
     "exception": false,
     "start_time": "2021-05-10T14:13:01.936141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 1792)\n",
      "CPU times: user 7.59 s, sys: 228 ms, total: 7.82 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if True:\n",
    "    IMAGE_SIZE = [384, 384]\n",
    "    effb4_embeddings = get_image_embeddings(image_paths, EFFNET_B4)\n",
    "    effb4_embeddings = np.apply_along_axis(norm, 1, effb4_embeddings)\n",
    "    \n",
    "    image_embeddings = np.concatenate([image_embeddings, effb4_embeddings], axis=1)\n",
    "    del effb4_embeddings; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047522,
     "end_time": "2021-05-10T14:13:13.229569",
     "exception": false,
     "start_time": "2021-05-10T14:13:13.182047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2.3 Effnet B4_2 (Mosaic aug, 456, loss 14.31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:13.331825Z",
     "iopub.status.busy": "2021-05-10T14:13:13.330967Z",
     "iopub.status.idle": "2021-05-10T14:13:23.446694Z",
     "shell.execute_reply": "2021-05-10T14:13:23.447266Z"
    },
    "papermill": {
     "duration": 10.170082,
     "end_time": "2021-05-10T14:13:23.447469",
     "exception": false,
     "start_time": "2021-05-10T14:13:13.277387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (3, 1792)\n",
      "CPU times: user 7.31 s, sys: 161 ms, total: 7.47 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if True:\n",
    "    IMAGE_SIZE = [456, 456]\n",
    "    effb4_2_embeddings = get_image_embeddings(image_paths, EFFNET_B4_2)\n",
    "    effb4_2_embeddings = np.apply_along_axis(norm, 1, effb4_2_embeddings)\n",
    "    \n",
    "    image_embeddings = np.concatenate([image_embeddings, effb4_2_embeddings], axis=1)\n",
    "    del effb4_2_embeddings; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048142,
     "end_time": "2021-05-10T14:13:23.544244",
     "exception": false,
     "start_time": "2021-05-10T14:13:23.496102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2.5 Effnet B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:23.646338Z",
     "iopub.status.busy": "2021-05-10T14:13:23.645445Z",
     "iopub.status.idle": "2021-05-10T14:13:23.649843Z",
     "shell.execute_reply": "2021-05-10T14:13:23.649240Z"
    },
    "papermill": {
     "duration": 0.057823,
     "end_time": "2021-05-10T14:13:23.650007",
     "exception": false,
     "start_time": "2021-05-10T14:13:23.592184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if False:\n",
    "    IMAGE_SIZE = [512, 512]\n",
    "    effb5_embeddings = get_image_embeddings(image_paths, EFFNET_B5)\n",
    "    effb5_embeddings = np.apply_along_axis(norm, 1, effb5_embeddings)\n",
    "    \n",
    "    image_embeddings.append(effb5_embeddings)\n",
    "    del effb5_embeddings; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048636,
     "end_time": "2021-05-10T14:13:23.747883",
     "exception": false,
     "start_time": "2021-05-10T14:13:23.699247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2.N All images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:23.849893Z",
     "iopub.status.busy": "2021-05-10T14:13:23.849309Z",
     "iopub.status.idle": "2021-05-10T14:13:23.852529Z",
     "shell.execute_reply": "2021-05-10T14:13:23.851986Z"
    },
    "papermill": {
     "duration": 0.056516,
     "end_time": "2021-05-10T14:13:23.852644",
     "exception": false,
     "start_time": "2021-05-10T14:13:23.796128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_embeddings = np.apply_along_axis(norm, 1, image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:23.954071Z",
     "iopub.status.busy": "2021-05-10T14:13:23.953278Z",
     "iopub.status.idle": "2021-05-10T14:13:23.957187Z",
     "shell.execute_reply": "2021-05-10T14:13:23.956705Z"
    },
    "papermill": {
     "duration": 0.05496,
     "end_time": "2021-05-10T14:13:23.957305",
     "exception": false,
     "start_time": "2021-05-10T14:13:23.902345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # basic image match\n",
    "# df, image_predictions = get_neighbors(df, image_embeddings, KNN = 51 if len(df)>3 else 3, th = 0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:24.061964Z",
     "iopub.status.busy": "2021-05-10T14:13:24.061222Z",
     "iopub.status.idle": "2021-05-10T14:13:24.064311Z",
     "shell.execute_reply": "2021-05-10T14:13:24.063864Z"
    },
    "papermill": {
     "duration": 0.055364,
     "end_time": "2021-05-10T14:13:24.064436",
     "exception": false,
     "start_time": "2021-05-10T14:13:24.009072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['image_predictions'] = image_predictions\n",
    "# del image_predictions; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:24.168022Z",
     "iopub.status.busy": "2021-05-10T14:13:24.166218Z",
     "iopub.status.idle": "2021-05-10T14:13:24.168574Z",
     "shell.execute_reply": "2021-05-10T14:13:24.168965Z"
    },
    "papermill": {
     "duration": 0.055785,
     "end_time": "2021-05-10T14:13:24.169120",
     "exception": false,
     "start_time": "2021-05-10T14:13:24.113335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tfidf_tensor = torch.from_numpy(tfidf_embeddings).to(device)\n",
    "# bert_tensor = torch.from_numpy(bert_embeddings).to(device)\n",
    "# del bert_embeddings,tfidf_embeddings; gc.collect()\n",
    "# tensor_concat_txt = torch.cat((tfidf_tensor, bert_tensor), 1)\n",
    "# tensor_concat_txt = tensor_concat_txt / torch.norm(tensor_concat_txt,2, 1).view([-1,1])\n",
    "# del tfidf_tensor, bert_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:24.531742Z",
     "iopub.status.busy": "2021-05-10T14:13:24.530917Z",
     "iopub.status.idle": "2021-05-10T14:13:24.534394Z",
     "shell.execute_reply": "2021-05-10T14:13:24.534807Z"
    },
    "papermill": {
     "duration": 0.317454,
     "end_time": "2021-05-10T14:13:24.534958",
     "exception": false,
     "start_time": "2021-05-10T14:13:24.217504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat\n",
    "tensor_concat_img = torch.from_numpy(image_embeddings).to(device)\n",
    "del image_embeddings; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048701,
     "end_time": "2021-05-10T14:13:24.632532",
     "exception": false,
     "start_time": "2021-05-10T14:13:24.583831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. Concat image & text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048879,
     "end_time": "2021-05-10T14:13:24.730388",
     "exception": false,
     "start_time": "2021-05-10T14:13:24.681509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3.1 Concat pred 51 : to recall stable matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:24.840256Z",
     "iopub.status.busy": "2021-05-10T14:13:24.839471Z",
     "iopub.status.idle": "2021-05-10T14:13:24.841808Z",
     "shell.execute_reply": "2021-05-10T14:13:24.842394Z"
    },
    "papermill": {
     "duration": 0.062528,
     "end_time": "2021-05-10T14:13:24.842538",
     "exception": false,
     "start_time": "2021-05-10T14:13:24.780010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_img_knn(df, tensor_concat_img, tfidf_tensor, bert_tensor, K, th_min, img_th_max, text_th_max, th_mean, th_top, chunk = 128):\n",
    "    out_preds = []\n",
    "    for i in tqdm(list(range(0, df.shape[0], chunk)) + [df.shape[0]-chunk]):\n",
    "        arr_img = tensor_concat_img[i : i + chunk] @ tensor_concat_img.T\n",
    "        arr_text = (tfidf_tensor[i : i + chunk] @ tfidf_tensor.T + bert_tensor[i : i + chunk] @ bert_tensor.T)*0.5\n",
    "#         arr_text = arr_text / torch.norm(arr_text, 2, 1).view([-1,1])\n",
    "        if len(df) > 3: \n",
    "            indices = torch.nonzero(\n",
    "                                    ((arr_img > th_top) | (arr_text > th_top)) | ((arr_img > th_min) & (arr_text > text_th_max)) | \n",
    "                                    ((arr_img > img_th_max) & (arr_text > th_min)) | (arr_img + arr_text > 2 * th_mean)\n",
    "\n",
    "#                                     & (arr_img >= arr_img.sort(descending=True).values[:,K-1].reshape(arr_img.shape[0],-1))\n",
    "#                                     & (arr_text >= arr_text.sort(descending=True).values[:,K-1].reshape(arr_text.shape[0],-1))\n",
    "                                   )\n",
    "        else:\n",
    "            indices = torch.nonzero(\n",
    "                                    ((arr_img > th_top) | (arr_text > th_top)) | ((arr_img > th_min) & (arr_text > text_th_max)) | \n",
    "                                    ((arr_img > img_th_max) & (arr_text > th_min)) | (arr_img + arr_text > 2 * th_mean)\n",
    "                                   )\n",
    "\n",
    "        preds = dict()\n",
    "        for k in range(arr_img.shape[0]):\n",
    "            preds[k] = []\n",
    "        for ind in range(indices.size(0)):\n",
    "            preds[indices[ind, 0].item()].append(indices[ind, 1].item())\n",
    "\n",
    "        out_preds.extend([(df.iloc[k].posting_id, df.iloc[v].posting_id.tolist()) for k, v in preds.items()])\n",
    "    return out_preds[:df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:24.948113Z",
     "iopub.status.busy": "2021-05-10T14:13:24.947339Z",
     "iopub.status.idle": "2021-05-10T14:13:25.322599Z",
     "shell.execute_reply": "2021-05-10T14:13:25.323223Z"
    },
    "papermill": {
     "duration": 0.43202,
     "end_time": "2021-05-10T14:13:25.323428",
     "exception": false,
     "start_time": "2021-05-10T14:13:24.891408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 113.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get image & test union pred\n",
    "out_preds = text_img_knn(df, tensor_concat_img, tfidf_tensor, bert_tensor, 51, th_min=0.1, img_th_max=0.74, text_th_max=0.82, th_mean=0.7, th_top=0.9)\n",
    "df_pred_concat = pd.DataFrame(out_preds, columns=[\"index\", \"pred\"])\n",
    "df['concat_predictions'] = df_pred_concat['pred']\n",
    "del out_preds, df_pred_concat; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.086506,
     "end_time": "2021-05-10T14:13:25.499851",
     "exception": false,
     "start_time": "2021-05-10T14:13:25.413345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3.2 Concat pred 2 : to improve match 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:25.620156Z",
     "iopub.status.busy": "2021-05-10T14:13:25.619332Z",
     "iopub.status.idle": "2021-05-10T14:13:25.896431Z",
     "shell.execute_reply": "2021-05-10T14:13:25.895983Z"
    },
    "papermill": {
     "duration": 0.334127,
     "end_time": "2021-05-10T14:13:25.896550",
     "exception": false,
     "start_time": "2021-05-10T14:13:25.562423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 342.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out_preds = text_knn_2(df, tensor_concat_img, tensor_concat_txt, K=2, th=0.5)\n",
    "out_preds = text_knn_3(df, tensor_concat_img, tfidf_tensor, bert_tensor, 1, 0.5, 0.5, K=2, th=0.6)\n",
    "df_match_1 = pd.DataFrame(out_preds, columns=[\"index\", \"pred\"])\n",
    "df['combo_pred_2'] = df_match_1['pred']\n",
    "del out_preds, df_match_1; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051895,
     "end_time": "2021-05-10T14:13:26.001363",
     "exception": false,
     "start_time": "2021-05-10T14:13:25.949468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3.3 Concat pred 2 : label propagation using strict thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:26.117385Z",
     "iopub.status.busy": "2021-05-10T14:13:26.116454Z",
     "iopub.status.idle": "2021-05-10T14:13:26.389267Z",
     "shell.execute_reply": "2021-05-10T14:13:26.389768Z"
    },
    "papermill": {
     "duration": 0.334023,
     "end_time": "2021-05-10T14:13:26.389932",
     "exception": false,
     "start_time": "2021-05-10T14:13:26.055909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 337.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out_preds = text_knn_2(df, tensor_concat_img, tensor_concat_txt, K=2, th=1.8)\n",
    "out_preds = text_knn_3(df, tensor_concat_img, tfidf_tensor, bert_tensor, 1, 0.5, 0.5, K=2, th=1.7)\n",
    "df_propa = pd.DataFrame(out_preds, columns=[\"index\", \"pred\"])\n",
    "df['combo_pred_propa'] = df_propa['pred']\n",
    "del out_preds, df_propa; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:26.763057Z",
     "iopub.status.busy": "2021-05-10T14:13:26.761694Z",
     "iopub.status.idle": "2021-05-10T14:13:26.764966Z",
     "shell.execute_reply": "2021-05-10T14:13:26.765390Z"
    },
    "papermill": {
     "duration": 0.320583,
     "end_time": "2021-05-10T14:13:26.765538",
     "exception": false,
     "start_time": "2021-05-10T14:13:26.444955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tensor_concat_img, tfidf_tensor, bert_tensor; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052827,
     "end_time": "2021-05-10T14:13:26.871249",
     "exception": false,
     "start_time": "2021-05-10T14:13:26.818422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:26.983132Z",
     "iopub.status.busy": "2021-05-10T14:13:26.982359Z",
     "iopub.status.idle": "2021-05-10T14:13:26.985453Z",
     "shell.execute_reply": "2021-05-10T14:13:26.984959Z"
    },
    "papermill": {
     "duration": 0.060822,
     "end_time": "2021-05-10T14:13:26.985579",
     "exception": false,
     "start_time": "2021-05-10T14:13:26.924757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_predictions_pp(row):\n",
    "#     x = np.concatenate([row['image_predictions'], row['tfidf_predictions']])\n",
    "#     x = np.concatenate([row['image_predictions'], row['tfidf_predictions'], row['concat_predictions']])\n",
    "    x = row['concat_predictions']\n",
    "    if len(x) > 50:\n",
    "        x = x[:50]\n",
    "    return np.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:27.098445Z",
     "iopub.status.busy": "2021-05-10T14:13:27.097837Z",
     "iopub.status.idle": "2021-05-10T14:13:27.105920Z",
     "shell.execute_reply": "2021-05-10T14:13:27.105485Z"
    },
    "papermill": {
     "duration": 0.065843,
     "end_time": "2021-05-10T14:13:27.106096",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.040253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['first_pred'] = df.apply(combine_predictions_pp, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056326,
     "end_time": "2021-05-10T14:13:27.218572",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.162246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### PP based on nb of matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:27.338649Z",
     "iopub.status.busy": "2021-05-10T14:13:27.337874Z",
     "iopub.status.idle": "2021-05-10T14:13:27.343070Z",
     "shell.execute_reply": "2021-05-10T14:13:27.342265Z"
    },
    "papermill": {
     "duration": 0.0703,
     "end_time": "2021-05-10T14:13:27.343232",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.272932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows processed\n",
      "Avg match item before pp : 1.0 | Avg match item after pp : 1.0\n"
     ]
    }
   ],
   "source": [
    "df['nb_first_pred'] = df['first_pred'].apply(len)\n",
    "\n",
    "# if use image + text\n",
    "df['second_pred'] = np.where(df.nb_first_pred<2, df.combo_pred_2, df.first_pred)\n",
    "\n",
    "df['nb_second_pred'] = df['second_pred'].apply(len)\n",
    "print(len(df[df.nb_first_pred!=df.nb_second_pred]), 'rows processed')\n",
    "print('Avg match item before pp :', df.nb_first_pred.mean(), '| Avg match item after pp :', df.nb_second_pred.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054089,
     "end_time": "2021-05-10T14:13:27.451689",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.397600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### PP based on symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:27.575826Z",
     "iopub.status.busy": "2021-05-10T14:13:27.575082Z",
     "iopub.status.idle": "2021-05-10T14:13:27.578209Z",
     "shell.execute_reply": "2021-05-10T14:13:27.577730Z"
    },
    "papermill": {
     "duration": 0.073026,
     "end_time": "2021-05-10T14:13:27.578338",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.505312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if first A->[], B->[C]\n",
    "# and second A->[B], B->[C]\n",
    "# then third A->[B], B->[C, A]\n",
    "if len(df)>3:\n",
    "    def get_comp_set(row):\n",
    "        return ' '.join(list(set(row['second_pred']) - set(row['first_pred'])))\n",
    "\n",
    "    df_1_to_2 = df[(df.nb_first_pred==1)&(df.nb_second_pred==2)][['first_pred', 'second_pred']]\n",
    "    df_1_to_2['second_pred_comp'] = df_1_to_2.apply(get_comp_set, axis = 1)\n",
    "    del df_1_to_2['second_pred']\n",
    "\n",
    "    dict_pp_comp = df_1_to_2.set_index('second_pred_comp').T.to_dict('list')\n",
    "    def update_pp(row):\n",
    "        if row['posting_id'] in dict_pp_comp:\n",
    "            return np.unique(np.concatenate([row['third_pred'], dict_pp_comp[row['posting_id']][0]]))\n",
    "        return row['third_pred']\n",
    "\n",
    "    df['third_pred'] = df['second_pred']\n",
    "    df['third_pred'] = df.apply(update_pp, axis=1)\n",
    "    df['nb_third_pred'] = df['third_pred'].apply(len)\n",
    "\n",
    "    print(len(df[df.nb_second_pred!=df.nb_third_pred]), 'rows processed')\n",
    "    print('Avg match item before pp :', df.nb_second_pred.mean(), '| Avg match item after pp :', df.nb_third_pred.mean())\n",
    "    \n",
    "    # propagation pp\n",
    "    cnt = 0\n",
    "    pp_dict_propa = {}\n",
    "    for index, row in df.iterrows():\n",
    "        item, matches = row['posting_id'], row['third_pred']\n",
    "        if len(matches) == 2:\n",
    "            p_matches = np.concatenate(df[df.posting_id.isin(matches)]['combo_pred_propa'].tolist())\n",
    "            if item in pp_dict_propa:\n",
    "                pp_dict_propa[item] = np.unique(np.concatenate([p_matches, pp_dict_propa[item]]))\n",
    "            else:\n",
    "                pp_dict_propa[item] = np.unique(np.concatenate([p_matches, matches]))\n",
    "        cnt += 1\n",
    "        if cnt % 5000 == 0: print('Checked :', cnt)\n",
    "            \n",
    "    def update(i):\n",
    "        return pp_dict_propa[i] if i in pp_dict_propa else df[df.posting_id==i]['third_pred'].values[0]\n",
    "    \n",
    "    if len(pp_dict_propa) > 0:\n",
    "        print(len(pp_dict_propa), 'values to update')\n",
    "        df['propa_pred'] = df['posting_id'].progress_apply(update)\n",
    "    else:\n",
    "        print(\"Nothing to update\")\n",
    "        df['propa_pred'] = df['third_pred']\n",
    "    df['nb_propa_pred'] = df['propa_pred'].apply(len)\n",
    "        \n",
    "    print(len(df[df.nb_propa_pred!=df.nb_third_pred]), 'rows processed')\n",
    "    print('Avg match item before pp :', df.nb_third_pred.mean(), '| Avg match item after pp :', df.nb_propa_pred.mean())\n",
    "    \n",
    "    df['third_pred'] = df['propa_pred']\n",
    "\n",
    "else:\n",
    "    df['third_pred'] = df['second_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:27.694115Z",
     "iopub.status.busy": "2021-05-10T14:13:27.693417Z",
     "iopub.status.idle": "2021-05-10T14:13:27.696688Z",
     "shell.execute_reply": "2021-05-10T14:13:27.697104Z"
    },
    "papermill": {
     "duration": 0.06514,
     "end_time": "2021-05-10T14:13:27.697240",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.632100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OOF LOGS'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"OOF LOGS\"\"\"\n",
    "\n",
    "# all\n",
    "\n",
    "# average effnetb3 & nfnet_l1 & effnetb4 & effnetb482 + bert + pp_propa\n",
    "# 0.24(4)/0.8/1.5-0.6-1.7 : 5.87(3554)/5.98(703)/6.00(249)/0.954\n",
    "# 0.24(4)/0.8/1.6-0.6-1.7 : 5.80(4500)/5.93(880)/5.96(356)/0.950\n",
    "# 0.22(4)/0.8/1.55-0.6-1.7 : 5.73(4666)/5.86(965)/5.90(378)/0.945 767\n",
    "# 0.22(4)/0.8/1.6-0.6-1.7 : 5.68(5222)/5.83(1068)/5.88(470)/0.942\n",
    "\n",
    "###############################\n",
    "\n",
    "# add concat_pred\n",
    "\n",
    "# baseline\n",
    "# 0.26/0.8/1.4-0.5 : 5.64/5.79(5152)/5.84(1648)/0.921 764\n",
    "\n",
    "# average effnetb3 & nfnet_l0\n",
    "# 0.26(2)/0.8/1.4-0.5 : 5.66/5.79(4587)/5.84(1453)/0.928 765\n",
    "\n",
    "# average effnetb3 & nfnet_l1\n",
    "# 0.24(2)/0.8/1.4-0.5 : 5.68/5.81(4421)/5.85(1330)/0.932 766\n",
    "# 0.26(2)/0.8/1.4-0.5 : 5.78/5.89(3904)/5.93(1168)/0.938\n",
    "\n",
    "# average effnetb3 & nfnet_l1 + bert\n",
    "# 0.24(2)/0.8/1.5-0.6 : 5.69/5.82(4309)/5.85(1015)/0.939 767\n",
    "\n",
    "# average effnetb3 & nfnet_l1 & effnetb4 + bert\n",
    "# 0.24(3)/0.8/1.5-0.6 : 5.75/5.87(4053)/5.90(930)/0.942 768\n",
    "\n",
    "# average effnetb3 & nfnet_l1 & effnetb3_2 & effnetb4 + bert\n",
    "# 0.24(4)/0.8/1.5-0.6 : 5.78/5.90(4099)/5.93(894)/0.945 768++\n",
    "\n",
    "# average effnetb3 & nfnet_l1 & effnetb3_2 & effnetb4 + average (tfidf+bert) + bert\n",
    "# 0.24(4)/1.6/1.5-0.6 : 5.60/5.72(4062)/5.74(730)/0.964\n",
    "# 0.24(4)/1.5/1.5-0.6 : 5.66/5.76(3455)/5.78(635)/0.966 768+\n",
    "\n",
    "# average effnetb3 & nfnet_l1 & effnetb5 + bert\n",
    "# 0.24(3)/0.8/1.5-0.6 : 5.62/5.76(4908)/5.80(1167)/0.932 767\n",
    "\n",
    "###############################\n",
    "\n",
    "# union effnetb3 & nfnet_l0\n",
    "# 0.26/0.28/0.8-0.5 : 5.84/5.95(3690)/5.99(1226)/0.935\n",
    "\n",
    "# average effnetb3 & nfnet_l0\n",
    "# 0.26(2)/0.8-0.5 : 5.56/5.73(5373)/5.78(1618)/0.923\n",
    "\n",
    "# baseline\n",
    "# 0.26/0.8-0.5 : 5.56/5.73(5871)/5.78(1799)/0.917 763\n",
    "\n",
    "\n",
    "\n",
    "# 5.861489051094891\n",
    "# Our final f1 cv score is 0.9793075685070094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054966,
     "end_time": "2021-05-10T14:13:27.806473",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.751507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Manual Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053913,
     "end_time": "2021-05-10T14:13:27.915102",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.861189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check cosine dist between 2 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:28.029347Z",
     "iopub.status.busy": "2021-05-10T14:13:28.028580Z",
     "iopub.status.idle": "2021-05-10T14:13:28.031560Z",
     "shell.execute_reply": "2021-05-10T14:13:28.031026Z"
    },
    "papermill": {
     "duration": 0.06102,
     "end_time": "2021-05-10T14:13:28.031678",
     "exception": false,
     "start_time": "2021-05-10T14:13:27.970658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from numpy import dot\n",
    "# from numpy.linalg import norm\n",
    "\n",
    "# df['nb_matches'] = df['matches'].apply(lambda x:len(x.split()))\n",
    "# df[(df.nb_second_pred==1)&(df.nb_matches==2)][['posting_id', 'matches', 'second_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:28.147425Z",
     "iopub.status.busy": "2021-05-10T14:13:28.145881Z",
     "iopub.status.idle": "2021-05-10T14:13:28.147960Z",
     "shell.execute_reply": "2021-05-10T14:13:28.148376Z"
    },
    "papermill": {
     "duration": 0.061937,
     "end_time": "2021-05-10T14:13:28.148516",
     "exception": false,
     "start_time": "2021-05-10T14:13:28.086579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df[(df.nb_third_pred==3)&(df.nb_matches==2)&(df.nb_second_pred==2)][['posting_id', 'f1', 'matches', 'second_pred', 'third_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:28.262833Z",
     "iopub.status.busy": "2021-05-10T14:13:28.262086Z",
     "iopub.status.idle": "2021-05-10T14:13:28.265713Z",
     "shell.execute_reply": "2021-05-10T14:13:28.265286Z"
    },
    "papermill": {
     "duration": 0.062111,
     "end_time": "2021-05-10T14:13:28.265828",
     "exception": false,
     "start_time": "2021-05-10T14:13:28.203717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df[df.posting_id=='train_1943466047'].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:28.384884Z",
     "iopub.status.busy": "2021-05-10T14:13:28.384041Z",
     "iopub.status.idle": "2021-05-10T14:13:28.386793Z",
     "shell.execute_reply": "2021-05-10T14:13:28.387296Z"
    },
    "papermill": {
     "duration": 0.065706,
     "end_time": "2021-05-10T14:13:28.387446",
     "exception": false,
     "start_time": "2021-05-10T14:13:28.321740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ind_a = 116\n",
    "\n",
    "# # only works when a have 2 matches\n",
    "# matches_a = df.iloc[ind_a]['matches'].split()\n",
    "# id_a = df.iloc[ind_a]['posting_id']\n",
    "# matches_b = list(set(matches_a) - set([id_a]))[0]\n",
    "# ind_b = df[df.posting_id==matches_b].index.values[0]\n",
    "\n",
    "# get cosine dist / val\n",
    "# a = image_embeddings[ind_a]\n",
    "# b = image_embeddings[ind_b]\n",
    "# print(\"Image cosine distance : \", round(1-dot(a, b)/(norm(a)*norm(b)),3))\n",
    "# a = text_embeddings[ind_a]\n",
    "# b = text_embeddings[ind_b]\n",
    "# print(\"Text cosine value     : \", round(dot(a, b)/(norm(a)*norm(b)),3))\n",
    "# a = bert_embeddings[ind_a]\n",
    "# b = bert_embeddings[ind_b]\n",
    "# print(\"Bert cosine distance : \", round(1-dot(a, b)/(norm(a)*norm(b)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:28.506662Z",
     "iopub.status.busy": "2021-05-10T14:13:28.505839Z",
     "iopub.status.idle": "2021-05-10T14:13:28.508922Z",
     "shell.execute_reply": "2021-05-10T14:13:28.508500Z"
    },
    "papermill": {
     "duration": 0.062552,
     "end_time": "2021-05-10T14:13:28.509073",
     "exception": false,
     "start_time": "2021-05-10T14:13:28.446521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = NearestNeighbors(n_neighbors = 2, metric = 'cosine')\n",
    "# model.fit(image_embeddings)\n",
    "# distances, indices = model.kneighbors(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:28.627644Z",
     "iopub.status.busy": "2021-05-10T14:13:28.626892Z",
     "iopub.status.idle": "2021-05-10T14:13:28.629826Z",
     "shell.execute_reply": "2021-05-10T14:13:28.629411Z"
    },
    "papermill": {
     "duration": 0.062117,
     "end_time": "2021-05-10T14:13:28.629947",
     "exception": false,
     "start_time": "2021-05-10T14:13:28.567830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distances[ind_a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:28.745397Z",
     "iopub.status.busy": "2021-05-10T14:13:28.744611Z",
     "iopub.status.idle": "2021-05-10T14:13:28.747086Z",
     "shell.execute_reply": "2021-05-10T14:13:28.747513Z"
    },
    "papermill": {
     "duration": 0.062059,
     "end_time": "2021-05-10T14:13:28.747655",
     "exception": false,
     "start_time": "2021-05-10T14:13:28.685596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# arr = text_tensor[34176] @ text_tensor.T\n",
    "# arr.sort(descending=True).values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:28.863058Z",
     "iopub.status.busy": "2021-05-10T14:13:28.862145Z",
     "iopub.status.idle": "2021-05-10T14:13:28.865432Z",
     "shell.execute_reply": "2021-05-10T14:13:28.864863Z"
    },
    "papermill": {
     "duration": 0.06221,
     "end_time": "2021-05-10T14:13:28.865552",
     "exception": false,
     "start_time": "2021-05-10T14:13:28.803342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = NearestNeighbors(n_neighbors = 51, metric = 'cosine')\n",
    "# model.fit(bert_embeddings)\n",
    "# distances, indices = model.kneighbors(bert_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055544,
     "end_time": "2021-05-10T14:13:28.976625",
     "exception": false,
     "start_time": "2021-05-10T14:13:28.921081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Check distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:29.101794Z",
     "iopub.status.busy": "2021-05-10T14:13:29.101039Z",
     "iopub.status.idle": "2021-05-10T14:13:29.103962Z",
     "shell.execute_reply": "2021-05-10T14:13:29.103564Z"
    },
    "papermill": {
     "duration": 0.061705,
     "end_time": "2021-05-10T14:13:29.104096",
     "exception": false,
     "start_time": "2021-05-10T14:13:29.042391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# N = 10\n",
    "# df_head_N = pd.DataFrame()\n",
    "# df_head_N['nb_first_pred'] = df.nb_first_pred.value_counts().sort_index().head(N)\n",
    "# df_head_N['nb_second_pred'] = df.nb_second_pred.value_counts().sort_index().head(N)\n",
    "# df_head_N['nb_third_pred'] = df.nb_third_pred.value_counts().sort_index().head(N)\n",
    "# df_head_N.head(N).T\n",
    "\n",
    "\n",
    "#                 1\t       2\t 3\t   4\t       5\t 6\t     7\t     8\t    9\t    10\n",
    "# nb_first_pred\t2367.0\t12380.0\t4896.0\t3372.0\t2218.0\t1654.0\t1008.0\t919.0\t790.0\t460.0\n",
    "# nb_second_pred\tNaN\t    14747.0\t4896.0\t3372.0\t2218.0\t1654.0\t1008.0\t919.0\t790.0\t460.0\n",
    "# nb_third_pred\tNaN\t    14541.0\t5042.0\t3391.0\t2245.0\t1661.0\t1008.0\t922.0\t791.0\t463.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:29.218867Z",
     "iopub.status.busy": "2021-05-10T14:13:29.218142Z",
     "iopub.status.idle": "2021-05-10T14:13:29.221060Z",
     "shell.execute_reply": "2021-05-10T14:13:29.220639Z"
    },
    "papermill": {
     "duration": 0.061632,
     "end_time": "2021-05-10T14:13:29.221181",
     "exception": false,
     "start_time": "2021-05-10T14:13:29.159549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(df['matches'].apply(lambda x:len(x.split())).value_counts().sort_index()).head(9).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:29.336243Z",
     "iopub.status.busy": "2021-05-10T14:13:29.335402Z",
     "iopub.status.idle": "2021-05-10T14:13:29.337508Z",
     "shell.execute_reply": "2021-05-10T14:13:29.337941Z"
    },
    "papermill": {
     "duration": 0.061864,
     "end_time": "2021-05-10T14:13:29.338096",
     "exception": false,
     "start_time": "2021-05-10T14:13:29.276232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ax = df['nb_third_pred'].value_counts().sort_index().plot.bar(figsize=(18,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:29.452387Z",
     "iopub.status.busy": "2021-05-10T14:13:29.451661Z",
     "iopub.status.idle": "2021-05-10T14:13:29.454567Z",
     "shell.execute_reply": "2021-05-10T14:13:29.454148Z"
    },
    "papermill": {
     "duration": 0.061578,
     "end_time": "2021-05-10T14:13:29.454684",
     "exception": false,
     "start_time": "2021-05-10T14:13:29.393106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ax = df['matches'].apply(lambda x:len(x.split())).value_counts().sort_index().plot.bar(figsize=(18,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055454,
     "end_time": "2021-05-10T14:13:29.565363",
     "exception": false,
     "start_time": "2021-05-10T14:13:29.509909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T14:13:29.684790Z",
     "iopub.status.busy": "2021-05-10T14:13:29.684221Z",
     "iopub.status.idle": "2021-05-10T14:13:29.778483Z",
     "shell.execute_reply": "2021-05-10T14:13:29.777180Z"
    },
    "papermill": {
     "duration": 0.157917,
     "end_time": "2021-05-10T14:13:29.778634",
     "exception": false,
     "start_time": "2021-05-10T14:13:29.620717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate image predctions with text predictions\n",
    "if GET_CV:\n",
    "    df['pred_matches'] = df['third_pred'].apply(lambda x:' '.join(x))\n",
    "    print(df['pred_matches'].apply(lambda x: len(x.split())).mean())\n",
    "    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "    score = df['f1'].mean()\n",
    "    print(f'Our final f1 cv score is {score}')\n",
    "#     df['matches'] = df['pred_matches']\n",
    "#     df[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "else:\n",
    "    df['matches'] = df['third_pred'].apply(lambda x:' '.join(x))\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 174.261478,
   "end_time": "2021-05-10T14:13:34.107731",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-10T14:10:39.846253",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "058dc42f186d47b0bcc0607521b3e9c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1990aec06f4042108cfe995fa7699f62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_460067d75f584b4bb43679d25bf0b046",
        "IPY_MODEL_32d365bb6d02416aaf9854f02fc5b48f",
        "IPY_MODEL_3d9d93c879304b1c9d3abb463d9355c8"
       ],
       "layout": "IPY_MODEL_89ff89899de649bf903430bf77537d32"
      }
     },
     "32d365bb6d02416aaf9854f02fc5b48f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_78e49eb62e0f41b7876019f78cab1ca7",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_058dc42f186d47b0bcc0607521b3e9c5",
       "value": 3.0
      }
     },
     "35208a218cec41d59794f0d4cbeec6c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d9d93c879304b1c9d3abb463d9355c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6ab09f70af2b4a50a8851bc90fe6018f",
       "placeholder": "​",
       "style": "IPY_MODEL_3f19d0d0d8af4ac782d209499232d22c",
       "value": " 3/3 [00:00&lt;00:00, 111.16it/s]"
      }
     },
     "3f19d0d0d8af4ac782d209499232d22c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "460067d75f584b4bb43679d25bf0b046": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_35208a218cec41d59794f0d4cbeec6c3",
       "placeholder": "​",
       "style": "IPY_MODEL_c547e5bac014433c8c91735e6c6bf633",
       "value": "100%"
      }
     },
     "6ab09f70af2b4a50a8851bc90fe6018f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78e49eb62e0f41b7876019f78cab1ca7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89ff89899de649bf903430bf77537d32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c547e5bac014433c8c91735e6c6bf633": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
